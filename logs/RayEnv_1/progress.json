{"hypers": {"envname": "RayEnv", "env": {"seed": 450, "n_envs": 4}, "framestack": {"n_stack": 4}, "agent": {"seed": 1450, "policy": "MlpPolicy", "learning_rate": 0.0007, "n_steps": 10, "gamma": 0.99, "gae_lambda": 1, "ent_coef": 0.01, "vf_coef": 0.25, "max_grad_norm": 0.5, "rms_prop_eps": 1e-05}, "learn": {"total_timesteps": 10000000.0, "log_interval": 100}}, "train/learning_rate": 0.0007, "train/n_updates": 99, "train/explained_variance": 0.0, "train/entropy_loss": -24.879085540771484, "train/policy_loss": 33219.8046875, "train/value_loss": 9315642.0, "time/iterations": 100, "time/fps": 171, "time/time_elapsed": 23, "time/total_timesteps": 4000}
{"train/learning_rate": 0.0007, "train/n_updates": 199, "train/explained_variance": 5.364418029785156e-07, "train/entropy_loss": -23.250585556030273, "train/policy_loss": 32827.3125, "train/value_loss": 8880152.0, "time/iterations": 200, "time/fps": 212, "time/time_elapsed": 37, "time/total_timesteps": 8000}
{"train/learning_rate": 0.0007, "train/n_updates": 299, "train/explained_variance": 0.0004526972770690918, "train/entropy_loss": -23.430747985839844, "train/policy_loss": 246.0423126220703, "train/value_loss": 135.70468139648438, "time/iterations": 300, "time/fps": 272, "time/time_elapsed": 44, "time/total_timesteps": 12000}
{"train/learning_rate": 0.0007, "train/n_updates": 399, "train/explained_variance": 0.0013219714164733887, "train/entropy_loss": -21.68837547302246, "train/policy_loss": 90.31935119628906, "train/value_loss": 22.80109214782715, "time/iterations": 400, "time/fps": 318, "time/time_elapsed": 50, "time/total_timesteps": 16000}
{"train/learning_rate": 0.0007, "train/n_updates": 499, "train/explained_variance": 0.002272188663482666, "train/entropy_loss": -20.400203704833984, "train/policy_loss": 158.81002807617188, "train/value_loss": 102.84577941894531, "time/iterations": 500, "time/fps": 331, "time/time_elapsed": 60, "time/total_timesteps": 20000}
{"train/learning_rate": 0.0007, "train/n_updates": 599, "train/explained_variance": 0.029859185218811035, "train/entropy_loss": -19.499011993408203, "train/policy_loss": 170.74948120117188, "train/value_loss": 105.00032043457031, "time/iterations": 600, "time/fps": 336, "time/time_elapsed": 71, "time/total_timesteps": 24000}
